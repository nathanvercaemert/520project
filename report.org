#+LATEX_HEADER: \usepackage{placeins}
#+TITLE: SAT Solver Project Report
#+SUBTITLE: CSC 520 Spring 2022 001
#+AUTHOR: Kasimir Schulz, Kelly Wang, Nathan Vercaemert
#+DATE: 2022-04-28
* Project Description
** What is the problem?
SAT, as a concept, is a problem being represented in the form of a Boolean expression. Boolean satisfiability (SAT) represents the idea of matching a sentence of propositional logic in conjunctive normal form (a Boolean formula) with a corresponding set of assignments to the propositional symbols that satisfies the sentence. For our project, we consider the Boolean expression to be the problem. If a solution (a set of assignments) exists that satisfies the formula, our solver can find that solution. Our goal is to find a solution to the SAT problem more efficient that simply assigning all of the permutations of possible assignments and checking the assignments until a solution is found. A simple way to understand what we work towards here: consider what we call "early termination". Once variables have been assigned, we have to iterate through all of the clauses of the expression to see if they are satisfied. If, while iterating, we find a clause that is unsatisfied, we can terminate the checking process and try a different assignment. We don't need to continue checking the rest of the clauses to see if they are satisfied once we have found a single clause that is unsatisfied. This extremely simple example of an optimization shows how changes in algorithm and approach can affect the speed at which a solution is found.
** Why does the problem matter?
It has been proven that every problem in NP can be reduced to the SAT problem. This is to say that the SAT problem is NP-Complete. The Cook-Levin Theorem is named after the scientist who proved this. For a problem to be in NP, it needs to have a solution-verification process that can be achieved in polynomial time. Most problems in our world are in NP, therefore most problems in our world can be reduced to SAT. From this we can conclude that a SAT solver can be used to solve most problems that we face! Improving and understanding how SAT solvers work is a valuable problem for a number of reasons. Here are some highlights:
- SAT provides a means of solving problems that have no polynomial-time solution. This is explored in [[*Example SAT Application][Example SAT Application]].
- SAT provides an alternative solution to problems with a very complex polynomial-time solution. Once a SAT solver has been implemented and optimized, any problem can be represented in terms that the solver can parse and solve. For many instances of many problems, this alternative can allow for rapid prototyping or ultimate solutions where implementing a polynomial-time solution would be more expensive in terms of real-world cost (time/money).
- Occasionally there are problems that have approximations that run in polynomial time but there is no known optimal solution. SAT provides the best means of obtaining the optimal solution in cases where the optimal solution is necessary and there is no known optimal algorithm.
*** Example SAT Application
** The plan for addressing the problem.
In general, we propose that our SAT solver can be used for a generic CNF Boolean expression. Real-world applications ([[*Example SAT Application][Example SAT Application]]) further specify the mechanics of the solving process for specific use cases, but we find that a general approach fits the scope of the project. Any improvement in finding a solution to the generic and random CNF formula allows for greater optimization for more specific problems. Note that, in this same spirit, we do not apply the idea of component analysis to our solver (the tow-fold reason also considers that our test data did not exhibit components). Our logic is that any improvement to the single-component approach will easily be extended to instances where the data contains multiple SAT problems that can be solved as components. We based the structure of our project on section 7.6 of our textbook. The specifics of the heuristics we used (and the details regarding how they relate to the textbook's structure) are outlined in [[*Details of our approach.][Details of our approach.]] We approach the heuristics and other related methods of SAT solving in order of complexity. Some optimizations, like the "early termination" feature mentioned previously (and in the textbook) are trivial (though significant) optimizations. Others are far more in-depth. Variable and value selection, and the optimizations that they overlap (for example: the pure-symbol heuristic), provide extensive gains in speed and allow for many variations of approach.There is often incompatibility between heuristics (for example: the degree heuristic conflicts with our "minimum remaining variable" heuristic). Other times, heuristics complement each other and can be combined. Our plan focuses on this branch of optimizations leaving the complexity of alternative backtracking, restarts, and indexing for the [[*Discussion][Discussion]] section. Our approach to the problem assumes that the data is represented in a standardized CNF form. Available test data indicates that this is the norm in the world of SAT solvers, and it can further be reasoned as an acceptable decision in that any problem expressed as a Boolean formula can further be reduced to CNF.
** Details of our approach.
The details of our approach are outline in terms of the general abstraction of our solver (including its mechanics), a description of our test data and how it relates to our problem/approach, and a case-by-case discussion of each optimization/heuristic we utilized. The first sub-section contains a detailed description of the implementation details of the solver itself. Note that we do not here discuss "early termination" because it has been previously covered and is trivial in comparison to the rest of our optimizations. Note that the heuristics and optimizations here share the umbrella of value/variable selection in CSP terms in that they affect the solver's decision of which variable or value to try assigning next. This umbrella does not limit our heuristics! As you will see (for example: LCV extends the pure-symbol heuristic), value/variable selection encompasses a broad range of SAT solver optimizations.
*** Test Data
We utilized a set of test data compiled explicitly for the sake of generating SAT solvers. The data repository contained many flavors of CNF expressions designed for different types of optimizations. Our approach focused on the most generic and general application of Boolean satisfiability, therefore we solely utilized the random CNF data. To give an example of the alternatives we opted to avoid: there is data structured to represent graph-coloring problems; this type of data outlines specific connections between the clauses that can be used to narrow the operation of the heuristics. This graph-coloring data (that we didn't use) provides a good illustration of how SAT solvers can be optimized for specific cases of Boolean logic (in this case structured to represent graphs). As is outlined in the [[*Optional: Other Baseline Approaches][Optional: Other Baseline Approaches]] section, the use of the random CNF data sets allow for our analysis of our solver to be extended to any problem in a general sense (any NP problem, that is). Any NP problem can be reduced to the form which our solver parses, thus the optimizations reflected in our analysis can be extended to any NP problem.
*** Degree Heuristic
We implemented multiple versions of the degree heuristic. We settled on an implementation that shared its functionality with our other heuristics, but we will discuss our earlier alternative in this section. In general, the degree heuristic can be thought of as picking the variable that affects the most clauses because it will be most likely to cause problems later if it is not selected. Thus this heuristic focuses on which variable to next try assigning. At each iteration of variable assignment, this heuristic considers all the clauses that have not yet been satisfied. We only consider unsatisfied clauses because the assignment of the remaining variables in satisfied clauses has no affect on obtaining a solution. A variables number of neighbors is the number of unsatisfied clauses in which it appears. The degree heuristic simply selects the variable that appears most frequently in unsatisfied clauses.
**** Note:
We originally evaluated the degree heuristic only once at the initialization of the solver and then assigned the variables in the order in which they were prioritized based on initial neighbor values. That is to say we made a priority queue of variables sorted by the number of clauses in which they appeared before any assignments. Interestingly this version of the heuristic actually functioned more efficiently that our final version. We opted for the less efficient version because it better reflects the theory of the degree heuristic (and we have another variable-selection heuristic that out-performs both). In theory, a degree heuristic would only consider a variable to be a neighbor if it is unassigned.
*** Minimum Remaining Variables
Note that the title of this heuristic is a play on the "minimum remaining value" heuristic that we learned in the context of CSP problems. The traditional "minimum remaining value" heuristic does not apply to SAT solvers (every variable has a domain of exactly {0, 1}), but we were able to design our own heuristic here that utilized a similar notion of clause with the least remaining unassigned variables. Note here also that this heuristic was developed with our instructor's assignment in mind. In response to our project proposal, we were instructed to develop our own heuristic. This heuristic out-performed our expectations turning out to provide the greatest increases in efficiency. The idea behind this heuristic is to (once again) consider only the unsatisfied clauses, and select a variable (randomly) from the clause with the lowest number of remaining unassigned variables. The concept of this heuristic is that this clause (the one with the least remaining variables) is going to be the trickiest to satisfy, so we might as well satisfy it first. Note that a variable is picked at random from the (remaining unassigned variables of the) clause and its value is assigned randomly.
*** Least Constraining Value
This heuristic was derived directly from our learned theory of CSP instances. In the context of a SAT solver, the concept is that we might as well pick the value for each variable that leaves other variables with the most freedom. Note that this heuristic is for value assignment. This heuristic assumes that it is operating on a variable that has already been picked for assignment, and thus is "stacks" with heuristics designed around variable selection. The operation of this heuristic is thus: consider, as usual, all of the unsatisfied clauses in which the variable appears and assign the value for which the literal will most often be satisfied. We developed a scoring mechanism that incremented a variables value based on its literals' signs and simply assigned True/False based on the sign of the score. This heuristic encompasses the "pure-symbol" optimization described in our text. When it comes time to assign a variable, if it only appears in one sign of literal, it will take on that sign! It actually goes as far as to extend the "pure-symbol" heuristic in that in considers only unsatisfied clauses, so it may better represent the needed value. Interestingly, this heuristic does not take into account unit clauses. Even if there is a unit clause with a literal of a particular sign, LCV may still assign the other value based on the frequency with which the opposite sign of the unit clause appears.
*** Unit Clause
We implemented a version of unit clause that can be combined with either the degree heuristic or the MRV heuristic. Note that this differs from the [[*Nested Unit Clause][Nested Unit Clause]] that will be discussed in the next subsection. The unit clause heuristic is a value selection heuristics, but unlike variable-selection heuristics, it can be combined with other value-selection heuristics (LCV) in that it can simply override LCV as more important. The notion of the unit clause heuristic is this: if there exist and unsatisfied clause with only one remaining unassigned variable, we must select the value for that variable that satisfies the clause. This heuristic is very expensive to implement. As discussed later, the cost of implementation was actually more expensive that the efficiency gained for small problem sizes.
*** Nested Unit Clause
Unlike the other described unit clause heuristic, we also implemented a unit clause heuristic nested within MRV. As will be elucidated in our [[*Discussion][Discussion]] section. The implementation details and mechanics of the solver itself often affected the theoretical efficiency of a heuristic. The MRV heuristic selected a variable from a clause with the lowest number of unassigned variables. It was easy for us to nest unit clause functionality into MRV. All we had to do was test to see if this variable was the only remaining unassigned variable, and if so, try assigning the correct value.
** Results
** Discussion
*** Heuristic Focus
The aspect of the problem on which each heuristic focuses affected both the development of the solver and the efficiency. The main two distinctions we approached were variable selection and value selection. At each iteration of assignment, we had to select which variable to which to assign and what value to assign. In the case of the degree heuristic and MRV this distinction was mutually exclusive, but we were able to configure value assignment such that the more important unit-clause selection overrode LCV. There was an interplay between the foci of the heuristics that slowed development. Often effort was duplicated between the development of separate heuristics. For example, we initially sought out to develop a heuristic that focused solely on resolving pure symbols, but later in our development process the LCV heuristic accomplished all and more of the original pure-symbol heuristic. You will notice in the [[*Results][Results]] section that the two separate implementations of the unit-clause heuristic have different effects on efficiency. The nested version only ever improves the efficiency, while the stand-alone version actually slows down smaller problem sizes. Obviously, if possible, we would opt for the nested version as it takes advantage of already-executed subproblems. This is further explored in [[*Heuristic Cost][Heuristic Cost]].
*** Heuristic Cost
As describe in [[*Solver Mechanics][Solver Mechanics]], we found that some of the heuristics were theoretically simple to understand but difficult to translate into the solver's logic. This was particularly notable in the transition from the smaller data sets (20 variable) into larger sets (50 variables) for our degree heuristic and unit-clause heuristic. What's happening here: for these heuristics, for each assignment, we are iterating through the entire problem. Iterating through the entire problem to decides which variable or value to assign takes more time for the smaller problem sets that it saves. We see this loss of efficiency go away as the problem size increases. With the bigger problem sets, a poor assignment risks a deeper level of backtracking. That is to say that it's more likely that a poor assignment early on will lead to a much deeper progression of what is in fact an impossible assignment. As the problem size grows, the O(n) cost of iterating through the entire problem becomes relatively cheaper and cheaper as the risk of a deeper and deeper backtrack increases.
*** Solver Mechanics
Defining mechanics - for the sake of our discussion, we refer to the working of the SAT solver (aside from the heuristics/optimizations) as the mechanics. This includes the data structures and representations.
**** Check-assigned:
Check-assigned is something we labeled that referred to how we assessed whether or not a variable's assignment caused a clause to be permanently unsatisfied. Simply put, we found that we didn't have to implement through every clause for every assignment. Only the clauses related to the recent assignment mattered. Simple changes in how the solver functioned greatly (as shown in the check-assigned [[Results][Results]]) improved the efficiency of the solver.
**** Data Structures:
As we implemented our solver, we found that maintaining particular data structures as attributes of the solver greatly improved efficiency. This was mentioned in the textbook with regards to indexing, but as the complexity of our heuristics increased, we saw similar opportunities. One particular data structure that greatly improved the flow of our solver was a "clauses in which this variable appears" structure. The cost of initializing a data structure with the list of references of containing-clause greatly improved multiple heuristics' efficiencies. Instead of having to iterate through all of the clauses to find where a variable appeared, this structure allowed faster retrieval. In the same respect, we noticed a discrepancy between theory and implementation where data structures were lacking. One particular example is discussed in [[*Potential Improvements][Potential Improvements]].
*** Potential Improvements
As mentioned in our section about data structures, there were opportunities for further optimizations in this area. We saw a need for maintaining a set or list of unsatisfied clauses. Instead of iterating through the problem for each assignment to determine which clauses were unsatisfied, it could have greatly improved efficiency if we stored and maintained a list of unsatisfied clauses. Another area ripe for improvements was "intelligent backtracking". In our implementation, we only ever backtracked to the previous variable's assignment. Perhaps maintaining conflict sets of assignments could have allowed us to backtrack further allowing us to resolve issues is a faster fashion. These improvements fell outside the scope of our project.
** Optional: Other Baseline Approaches
As the SAT problem is most often considered as a solution to the NPC problem, we view our non-heuristic results as the baseline approach to an NPC problem. Theoretically this baseline entails the problem having been represented in the appropriate format, but that is not necessary for the comparison. The "brute force" approach often utilized as the first attempt at solving a solving a problem is represented by our solver without the utilization of any heuristics. This data contains the notion of simply trying each potential solution and seeing if it satisfies the problem. In terms of the Traveling SalesPerson problem, this could be understood as trying each tour and saving the minimum total distance/tour. Extending the idea to our SAT solver, the improvements shown in the [[*Results][Results]] section outline explicitly how our optimizations compare to the baseline. These same improvements would be seen in the application to a TSP instance or any other problem passed to the solver.
